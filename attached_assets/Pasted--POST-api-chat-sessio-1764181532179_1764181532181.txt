Пайплайн чата с кастомным навыком

Инициализация запроса

Фронт отправляет POST /api/chat/sessions/:id/messages/llm с content и skillId (чат уже привязан к навыку).
Бэкенд извлекает пользователя (getAuthorizedUser) и рабочее пространство (getRequestWorkspace), валидирует доступ к чату.
Запись пользовательского сообщения

Через writeUserMessage добавляем сообщение с ролью user в chat_messages.
В skill‑execution логе фиксируется шаг WRITE_USER_MESSAGE.
Построение контекста сессии

buildChatLlmContext загружает чат, историю сообщений, навык (SkillDto) и его конфиг (skillConfig, ragConfig, привязанные базы/коллекции).
В execution‑контексте появляется признак skill.isRagSkill (все кастомные навыки).
Ветвление: кастомный навык → RAG

Условие context.skill.isRagSkill срабатывает, поэтому чистый LLM‑путь пропускается.
Подготавливается ragStepInput (chatId, workspaceId, skillId, knowledgeBaseId) для логирования CALL_RAG_PIPELINE.
Сбор параметров RAG

Хелпер buildSkillRagRequestPayload берёт из skill.ragConfig:
режим (all_collections / selected_collections),
коллекции (collectionIds + валидация принадлежности workspace),
embeddingProviderId,
топ‑K, minScore, лимиты BM25/vector, showSources,
LLM‑конфиг (provider, модель, temperature, maxTokens, systemPrompt, responseFormat).
Если чего‑то критичного нет (коллекция, embedding, модель) — кидает SkillRagConfigurationError → пользователь получает понятное сообщение.
Запуск RAG‑пайплайна

callRagForSkillChat вызывает runKnowledgeBaseRagPipeline, передавая подготовленный payload:
{
  "q": "...",
  "kb_id": "...",
  "collection": "...",
  "embedding_provider_id": "...",
  "llm": { "provider": "...", "model": "...", ... },
  "hybrid": { "bm25": {...}, "vector": {...} }
}
Внутри runKnowledgeBaseRagPipeline происходит:
поиск по BM25 (storage.searchKnowledgeBaseSuggestions),
при наличии vector‑части — генерация эмбеддинга, запрос в Qdrant (через workspace‑API),
комбинирование результатов, ограничения по токенам,
вызов LLM для генерации ответа (с контекстом),
формирование ответа с полями answer, citations, usage, knowledgeBaseId.
Обработка результата

Шаг CALL_RAG_PIPELINE в execution‑логе помечается SUCCESS, сохраняются preview ответа, usage и kb_id.
Ответ (ragResult.response.answer) записывается как assistant‑сообщение через writeAssistantMessage, вместе с метаданными (citations, usage).
Финальный HTTP‑ответ возвращает:
{
  "message": {...assistant...},
  "userMessage": {...user...},
  "usage": {...},
  "rag": {
    "knowledgeBaseId": "...",
    "normalizedQuery": "...",
    "citations": [...]
  }
}
Execution завершается skillExecutionLogService.finish(SKILL_EXECUTION_STATUS.SUCCESS).
Что видит пользователь

В UI пользователь сразу получает своё сообщение; после обработки — ответ ассистента.
Если RAG конфиг не настроен (нет embedding или коллекций), он получает понятную 4xx ошибку, и лог фиксирует CALL_RAG_PIPELINE → ERROR.
Так обрабатывается каждый запрос диалога в кастомном навыке: всегда через существующий RAG‑эндпоинт, с параметрами из ragConfig и журналированием шагов в skill_execution.